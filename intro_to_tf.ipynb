{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro-to-tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObMRiKaIlN4C0zl87iim6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehom/colab_notebooks/blob/main/intro_to_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II0bSoCJdaOa"
      },
      "source": [
        "# Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z59ZEh10rv9C"
      },
      "source": [
        "https://www.coursera.org/learn/introduction-tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIc4UGc8dHRX"
      },
      "source": [
        "## Week 1: A New Programming Paradigm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3vFsjpUdxgk"
      },
      "source": [
        "### Practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIM5m3WbXuLu"
      },
      "source": [
        "#### Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsapfgGQNAyl"
      },
      "source": [
        "#!pip install tensorflow == 2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMdBZ3aSKPOd"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20_ZNsmKPwT",
        "outputId": "1bc9d9ad-6ee2-4fa6-be49-36304bbcca85"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "\n",
        "print(\"Tensor Flow version: {}\".format(tf.__version__))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor Flow version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AlrRgtQOKYI"
      },
      "source": [
        "#### Define and Compile the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlstsL4XOKvf"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd', loss=\"mean_squared_error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjX1330xOXPk"
      },
      "source": [
        "#### Provide the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld6WYg04LI5I"
      },
      "source": [
        "\n",
        "xs = np.array([1, 2, 3])\n",
        "ys = np.array([50, 100, 150])\n",
        "\n",
        "# print(xs)\n",
        "# print(ys)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pk9yj4LOBof"
      },
      "source": [
        "#### Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQEhqurrOB96"
      },
      "source": [
        "model.fit(xs, ys, epochs=500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-TOY9-NuGoE"
      },
      "source": [
        "#### Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmR5o9xXNdlP",
        "outputId": "88f7b7f0-eac0-4eab-e05f-774fe4d9194c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[195.68135]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYNrGN4jd_zf"
      },
      "source": [
        "### Assignment 1: Housing Prices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fQsxg_0QcJ6"
      },
      "source": [
        "In this exercise, you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
        "\n",
        "So, imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
        "\n",
        "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
        "\n",
        "**Hint**: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS5mVRvMQkBo",
        "outputId": "472d7618-77e4-493f-97c4-0c605739732e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "\n",
        "def house_model(X_new):\n",
        "    xs = np.array([1, 2, 3, 4, 5, 6, 7])\n",
        "    ys = np.array([100, 150, 200, 250, 300, 350, 400])\n",
        "\n",
        "    model = keras.Sequential([\n",
        "      keras.layers.Dense(units=1, input_shape=[1])\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='sgd', loss=\"mean_squared_error\")\n",
        "\n",
        "    model.fit(xs, ys, epochs=500)\n",
        "\n",
        "    return model.predict(X_new)[0]\n",
        "\n",
        "prediction = house_model([4])\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 71053.3906\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24413.0625\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8513.0801\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3091.7097\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1242.2458\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 610.3646\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 393.5375\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 318.2033\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 291.1111\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 280.4743\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 275.4576\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 272.3671\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 269.9440\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 267.7588\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 265.6651\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 263.6132\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 261.5856\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 259.5764\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 257.5836\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 255.6065\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 253.6449\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 251.6983\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 249.7666\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 247.8497\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 245.9475\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 244.0599\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 242.1868\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 240.3282\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 238.4837\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 236.6534\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 234.8372\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 233.0349\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 231.2465\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 229.4718\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 227.7108\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 225.9631\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 224.2289\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 222.5079\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 220.8003\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 219.1057\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 217.4242\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 215.7556\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 214.0997\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 212.4563\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 210.8260\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 209.2079\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 207.6024\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 206.0090\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 204.4281\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 202.8592\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 201.3024\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 199.7574\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 198.2242\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 196.7029\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 195.1932\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 193.6952\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 192.2088\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 190.7335\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 189.2699\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 187.8172\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 186.3758\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 184.9454\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 183.5260\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 182.1174\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 180.7199\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 179.3329\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 177.9565\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 176.5907\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 175.2355\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 173.8907\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 172.5562\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 171.2319\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 169.9176\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 168.6137\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 167.3195\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 166.0354\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 164.7611\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 163.4967\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 162.2419\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 160.9968\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 159.7610\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 158.5350\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 157.3183\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 156.1110\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 154.9129\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 153.7240\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 152.5441\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 151.3736\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 150.2117\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 149.0589\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 147.9149\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 146.7798\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 145.6532\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 144.5355\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 143.4262\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 142.3253\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 141.2330\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 140.1493\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 139.0736\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 138.0064\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 136.9470\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 135.8961\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 134.8532\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 133.8182\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 132.7912\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 131.7720\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 130.7609\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 129.7571\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 128.7614\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 127.7732\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 126.7925\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 125.8195\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 124.8538\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 123.8956\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 122.9447\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 122.0011\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 121.0648\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 120.1357\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 119.2138\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 118.2989\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 117.3908\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 116.4900\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 115.5960\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 114.7088\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 113.8284\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 112.9549\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 112.0879\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 111.2277\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 110.3741\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 109.5271\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 108.6863\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 107.8523\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 107.0247\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 106.2032\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 105.3882\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 104.5793\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 103.7767\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 102.9802\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 102.1899\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 101.4057\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 100.6273\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 99.8551\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 99.0887\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 98.3281\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 97.5735\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 96.8248\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 96.0817\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 95.3443\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 94.6126\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 93.8865\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 93.1659\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 92.4508\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 91.7413\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 91.0372\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 90.3386\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 89.6452\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 88.9572\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 88.2745\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 87.5970\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 86.9247\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 86.2575\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 85.5956\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 84.9387\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 84.2868\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 83.6400\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 82.9981\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 82.3611\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 81.7291\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 81.1018\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 80.4793\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 79.8616\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 79.2488\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 78.6406\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 78.0369\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 77.4381\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 76.8438\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 76.2541\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 75.6688\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 75.0881\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 74.5118\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 73.9399\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 73.3724\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 72.8094\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 72.2506\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 71.6960\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 71.1459\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 70.5999\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 70.0580\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 69.5203\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 68.9867\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 68.4574\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 67.9319\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 67.4106\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 66.8932\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 66.3799\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 65.8704\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 65.3648\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 64.8632\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 64.3654\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 63.8715\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.3813\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.8947\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.4122\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 61.9331\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 61.4578\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.9861\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 60.5182\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.0536\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 59.5927\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 59.1354\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 58.6816\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 58.2312\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 57.7843\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.3408\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 56.9007\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.4641\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 56.0308\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 55.6007\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 55.1740\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 54.7506\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 54.3304\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 53.9134\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 53.4996\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 53.0891\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 52.6815\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 52.2773\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 51.8760\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 51.4779\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 51.0829\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 50.6908\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 50.3017\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 49.9158\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 49.5327\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 49.1525\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.7753\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.4009\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.0295\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.6609\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 47.2950\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.9321\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 46.5719\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 46.2145\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 45.8598\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.5078\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 45.1586\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8120\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 44.4681\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.1268\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.7881\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 43.4521\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.1186\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 42.7878\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.4594\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1335\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.8101\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.4892\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.1708\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.8548\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 40.5413\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.2301\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.9213\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 39.6150\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 39.3110\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 39.0093\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.7099\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 38.4128\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 38.1180\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 37.8255\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 37.5352\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 37.2471\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 36.9612\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 36.6775\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 36.3961\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 36.1167\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 35.8395\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.5645\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.2915\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.0207\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 34.7519\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 34.4853\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 34.2206\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 33.9579\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 33.6973\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 33.4387\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 33.1821\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 32.9275\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 32.6747\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 32.4240\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 32.1751\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 31.9281\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 31.6831\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 31.4400\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 31.1987\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 30.9593\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 30.7217\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 30.4859\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 30.2519\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 30.0197\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 29.7893\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 29.5607\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 29.3338\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 29.1087\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 28.8853\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 28.6636\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.4436\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.2253\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 28.0087\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.7938\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.5805\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 27.3688\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 27.1588\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 26.9503\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 26.7435\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 26.5383\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 26.3346\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 26.1324\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 25.9319\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 25.7329\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 25.5354\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 25.3394\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 25.1449\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 24.9520\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 24.7605\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.5705\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 24.3819\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 24.1948\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 24.0091\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 23.8248\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 23.6420\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 23.4606\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 23.2804\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.1018\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.9245\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 22.7486\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 22.5740\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 22.4008\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 22.2288\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 22.0583\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 21.8890\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.7209\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 21.5543\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 21.3888\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.2247\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.0618\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.9001\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 20.7397\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.5806\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 20.4226\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 20.2659\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 20.1103\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.9560\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.8028\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.6509\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.5000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 19.3504\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.2019\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.0545\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.9083\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.7632\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18.6192\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.4763\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 18.3345\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.1938\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.0541\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 17.9156\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 17.7781\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 17.6417\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.5062\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.3719\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.2386\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 17.1062\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 16.9750\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 16.8447\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 16.7155\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.5871\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.4598\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.3335\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.2081\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.0838\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.9603\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.8378\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 15.7163\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.5957\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 15.4760\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.3572\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 15.2394\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.1224\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 15.0064\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.8911\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.7769\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.6635\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.5510\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 14.4393\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.3284\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.2185\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 14.1094\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.0011\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 13.8936\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.7870\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.6812\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.5762\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.4720\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.3686\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.2660\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 13.1642\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.0632\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.9629\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.8634\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.7647\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.6668\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.5695\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.4731\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.3773\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2824\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.1881\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.0946\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.0017\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.9096\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.8182\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.7275\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.6375\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.5482\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.4596\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3717\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2843\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.1978\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1118\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0266\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.9419\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.8580\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7746\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6919\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6098\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5284\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.4477\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.3675\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.2879\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.2089\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1306\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0529\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.9757\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.8991\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.8232\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7477\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6730\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.5987\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.5251\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.4520\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3794\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3074\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2360\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.1651\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0948\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0250\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.9557\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.8870\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.8188\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7511\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6839\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6173\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5512\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.4855\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.4204\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3558\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2917\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2280\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1649\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1022\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.0400\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.9784\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9171\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8563\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7960\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7362\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6769\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6179\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5595\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5015\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4439\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.3868\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3301\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.2738\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2180\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1626\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1076\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0531\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9990\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9452\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8919\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8391\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7865\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7345\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6828\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6315\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.5806\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5301\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4800\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4303\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3809\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3319\n",
            "[248.92271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHKFVGMWw71C",
        "outputId": "a2b07585-e06b-4700-ca67-c9ca68d73e0c"
      },
      "source": [
        "class Predictor:\n",
        "  def __init__(self):\n",
        "    xs = np.array([1, 2, 3, 4, 5, 6, 7])\n",
        "    ys = np.array([100, 150, 200, 250, 300, 350, 400])\n",
        "\n",
        "    self.model = keras.Sequential([\n",
        "      keras.layers.Dense(units=1, input_shape=[1])\n",
        "    ])\n",
        "\n",
        "    self.model.compile(optimizer='sgd', loss=\"mean_squared_error\")\n",
        "\n",
        "    self.model.fit(xs, ys, epochs=500)\n",
        "\n",
        "  def perform(self, number_of_bedrooms):\n",
        "    return self.model.predict(number_of_bedrooms).tolist()[0]\n",
        "\n",
        "\n",
        "predictor = Predictor()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 69250.8359\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 23800.1074\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8305.6143\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3022.4543\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1220.0922\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 604.2563\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 392.8872\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 319.4023\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 292.9299\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 282.4936\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 277.5345\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 274.4531\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 272.0223\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 269.8242\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 267.7155\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 265.6481\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 263.6051\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 261.5806\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 259.5726\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 257.5800\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 255.6032\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 253.6414\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 251.6949\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 249.7633\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 247.8463\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 245.9442\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 244.0567\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 242.1836\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 240.3251\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 238.4807\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 236.6504\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 234.8342\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 233.0318\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 231.2432\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 229.4685\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 227.7076\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 225.9599\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 224.2259\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 222.5051\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 220.7973\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 219.1028\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 217.4212\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 215.7526\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 214.0968\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 212.4538\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 210.8232\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 209.2052\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 207.5994\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 206.0063\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 204.4252\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 202.8563\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 201.2995\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 199.7546\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 198.2215\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 196.7002\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 195.1907\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 193.6926\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 192.2062\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 190.7309\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 189.2673\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 187.8147\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 186.3732\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 184.9430\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 183.5235\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 182.1151\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 180.7175\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 179.3305\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 177.9542\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 176.5884\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 175.2333\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 173.8883\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 172.5538\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 171.2294\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 169.9154\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 168.6113\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 167.3171\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 166.0332\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 164.7589\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 163.4944\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 162.2396\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 160.9946\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 159.7590\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 158.5329\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 157.3162\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 156.1089\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 154.9108\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 153.7217\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 152.5421\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 151.3714\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 150.2096\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 149.0568\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 147.9129\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 146.7778\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 145.6512\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 144.5334\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 143.4241\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 142.3234\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 141.2311\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 140.1473\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 139.0717\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 138.0044\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 136.9452\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 135.8943\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 134.8514\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 133.8163\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 132.7894\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 131.7703\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 130.7589\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 129.7554\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 128.7595\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 127.7714\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 126.7909\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 125.8178\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 124.8522\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 123.8939\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 122.9432\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 121.9995\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 121.0632\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 120.1341\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 119.2122\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 118.2972\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 117.3894\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 116.4884\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 115.5944\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 114.7073\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 113.8270\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 112.9533\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 112.0864\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 111.2262\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 110.3727\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 109.5255\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 108.6849\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 107.8509\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 107.0232\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 106.2017\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 105.3867\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 104.5779\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 103.7753\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 102.9789\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 102.1886\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 101.4043\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 100.6261\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 99.8538\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 99.0874\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 98.3269\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 97.5723\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 96.8235\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 96.0805\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 95.3429\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 94.6114\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 93.8852\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 93.1646\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 92.4496\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 91.7401\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 91.0361\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 90.3374\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 89.6441\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 88.9562\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 88.2733\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 87.5960\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 86.9237\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 86.2566\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 85.5946\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 84.9376\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 84.2858\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 83.6389\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 82.9970\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 82.3600\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 81.7280\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 81.1007\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 80.4784\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 79.8606\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 79.2476\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 78.6396\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 78.0360\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 77.4371\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 76.8428\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 76.2531\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 75.6678\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 75.0871\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 74.5109\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 73.9389\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 73.3716\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 72.8084\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 72.2497\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 71.6952\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 71.1450\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 70.5989\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 70.0570\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 69.5195\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 68.9859\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 68.4565\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 67.9311\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 67.4097\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 66.8924\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 66.3790\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 65.8696\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 65.3641\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 64.8625\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 64.3647\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.8706\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 63.3804\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.8940\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.4113\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 61.9324\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 61.4571\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.9854\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 60.5173\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.0529\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 59.5920\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 59.1347\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 58.6809\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 58.2305\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 57.7836\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 57.3401\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 56.9001\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 56.4633\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 56.0300\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 55.6000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 55.1733\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 54.7499\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 54.3297\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 53.9128\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 53.4989\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.0884\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 52.6810\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 52.2767\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.8755\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 51.4773\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 51.0822\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 50.6902\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.3012\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 49.9151\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.5321\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.1519\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 48.7747\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 48.4004\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.0289\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 47.6603\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.2946\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.9315\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.5714\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.2140\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 45.8593\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.5073\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.1580\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 44.8115\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 44.4676\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.1263\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.7877\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 43.4515\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1181\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 42.7872\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.4588\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1329\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.8095\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.4887\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 41.1703\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 40.8543\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.5407\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.2296\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.9209\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.6145\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 39.3105\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.0088\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.7095\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 38.4124\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 38.1175\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.8250\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 37.5347\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.2466\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 36.9607\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.6771\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.3956\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 36.1162\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.8390\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.5640\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.2911\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.0202\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 34.7515\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 34.4848\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 34.2201\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 33.9575\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 33.6969\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 33.4382\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 33.1816\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 32.9270\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 32.6743\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 32.4235\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 32.1747\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.9278\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 31.6828\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 31.4395\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 31.1983\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 30.9589\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 30.7212\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 30.4854\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 30.2514\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 30.0193\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 29.7889\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 29.5602\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 29.3335\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 29.1083\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.8849\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 28.6632\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.4433\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 28.2250\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 28.0083\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 27.7934\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 27.5801\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 27.3684\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 27.1583\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 26.9499\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.7431\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.5379\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.3342\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 26.1321\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.9315\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 25.7326\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 25.5350\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.3391\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 25.1446\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.9516\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.7601\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.5701\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 24.3815\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 24.1944\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 24.0088\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 23.8245\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 23.6416\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 23.4602\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.2801\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 23.1014\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.9242\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 22.7483\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.5736\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 22.4004\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.2285\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 22.0579\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.8886\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 21.7206\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 21.5539\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.3885\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.2243\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.0614\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 20.8998\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 20.7394\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 20.5803\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.4223\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.2656\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.1101\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.9557\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 19.8026\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.6505\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.4998\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.3501\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 19.2016\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.0542\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 18.9079\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.7629\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 18.6189\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 18.4760\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18.3342\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.1935\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.0539\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.9153\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.7778\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.6414\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.5060\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 17.3716\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 17.2382\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 17.1060\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 16.9747\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.8444\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 16.7151\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.5869\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 16.4596\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.3333\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.2079\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.0835\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.9601\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.8376\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.7160\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 15.5954\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.4757\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.3570\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.2391\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.1221\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.0061\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.8909\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.7766\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.6633\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.5507\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.4391\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.3282\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.2182\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.1091\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.0008\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.8934\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.7868\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 13.6810\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.5760\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.4718\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.3684\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.2658\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.1640\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.0630\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.9627\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.8633\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 12.7645\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.6666\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.5694\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 12.4729\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.3772\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.2822\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.1879\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0944\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.0016\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.9094\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.8181\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.7273\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6373\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.5480\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.4594\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.3715\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11.2842\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.1976\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.1116\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0264\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9418\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8578\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7744\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.6917\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6097\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.5283\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4475\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3673\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.2877\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.2088\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.1304\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0527\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9755\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8990\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.8230\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7476\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6728\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.5986\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5249\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4518\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.3792\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3073\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.2358\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.1650\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0946\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0248\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9556\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8868\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8186\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7509\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.6838\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6172\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.5510\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4854\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4203\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.3556\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2915\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.2279\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1647\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1021\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0399\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9782\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9170\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8562\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7959\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7361\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6767\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6178\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5594\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5013\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4437\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3866\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3299\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2737\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2178\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1625\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1075\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0530\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9988\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9451\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8918\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8389\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7864\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7343\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6827\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.6314\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.5805\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5300\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4799\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4301\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poJk7zalxjS7",
        "outputId": "3bc7532b-5a3e-4d4d-b6c4-f44d0ec91c59"
      },
      "source": [
        "predictor.perform([8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[453.4626770019531]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUQDalUHfIjE"
      },
      "source": [
        "## Week 2: Introduction to Computer Vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vejupDhxfTR2"
      },
      "source": [
        "!pip install tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQcgVkg5hUJx",
        "outputId": "dbc550a5-17c1-4c24-d433-64e4fd24aab4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QowDdjSuiDQH"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "2yAJd2CNjAi6",
        "outputId": "2fb38a54-849f-441a-b1fd-39e10af2448c"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjxuKIjkjJWi"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQGzBDosjr1r"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N08eGH2Oj6Xg",
        "outputId": "55553e60-6cdc-4ec6-cc48-e3bea2c70b98"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4982 - accuracy: 0.8249\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3731 - accuracy: 0.8643\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3359 - accuracy: 0.8781\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3083 - accuracy: 0.8867\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2951 - accuracy: 0.8918\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d2979d8d0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHsagfagkDBF",
        "outputId": "44a24d49-4614-4e07-95e9-347602263e85"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZCMU6czbkW7",
        "outputId": "559b305e-766e-46be-ef41-16ed6ce5fc15"
      },
      "source": [
        "print(\"Loss: {}\".format(loss))\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.3572263717651367\n",
            "Accuracy: 0.8715000152587891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dax8OFCpAIL"
      },
      "source": [
        "### Exploration Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdTpd6QapKSo"
      },
      "source": [
        "#### Lab 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tct1NbAnlGHk"
      },
      "source": [
        "# Creates a set of classifications for each of the test images, and then \n",
        "# print the first entry in the classifications. \n",
        "\n",
        "classifications = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn4GeUdxeQcQ",
        "outputId": "e7fc6f57-fc7c-4544-ff9a-7da2dcd272d5"
      },
      "source": [
        "from pprint import PrettyPrinter\n",
        "pp = PrettyPrinter(indent=4, width=1)\n",
        "\n",
        "# The output, after you run it, is a list of numbers. \n",
        "# Why do you think this is, and what do those numbers represent?\n",
        "\n",
        "pp.pprint(classifications[0].tolist())\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0.0,\n",
            "    0.0,\n",
            "    1.0,\n",
            "    0.0,\n",
            "    0.0,\n",
            "    0.0,\n",
            "    0.0,\n",
            "    0.0,\n",
            "    0.0,\n",
            "    0.0]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfBtxDSjpSvZ"
      },
      "source": [
        "#### Lab 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl9TbtPXpYCH"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "class Dataset:\n",
        "  images = None\n",
        "  labels = None\n",
        "\n",
        "training_data = Dataset()\n",
        "test_data = Dataset()\n",
        "\n",
        "(training_data.images, training_data.labels), (test_data.images, test_data.labels) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8T95dKpdOyA",
        "outputId": "d26dc3b5-219f-4f9f-fd6d-8e7992bfd8ab"
      },
      "source": [
        "training_data.images = training_data.images / 255.0\n",
        "test_data.images = test_data.images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1024, activation=tf.nn.relu), # Try experimenting with this layer\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_data.images, training_data.labels, epochs=5)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data.images, test_data.labels)\n",
        "\n",
        "print(\"test_loss: {}\".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.7268 - accuracy: 0.8119\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3320 - accuracy: 0.9050\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2886 - accuracy: 0.9165\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2586 - accuracy: 0.9244\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2322 - accuracy: 0.9332\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9383\n",
            "test_loss: 0.21589434146881104\n",
            "test_accuracy: 0.9383000135421753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6NNdoo4dhkU",
        "outputId": "a3dbbc20-6dcc-482f-b130-394a4f356074"
      },
      "source": [
        "classifications = model.predict(test_data.images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_data.labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.2395551e-04 2.2526843e-08 6.8353128e-04 3.6529773e-03 1.8115895e-07 6.2677806e-05 1.1225899e-09 9.9475187e-01 3.8879549e-05 6.8585231e-04]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySY_ATl6sa3f"
      },
      "source": [
        "Now let's run it without the first layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "EN8_GhwTq_Zr",
        "outputId": "3ac5033f-9586-4923-977e-623015091d70"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  # tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0ff6f6f3c282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_structure\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mismatch in element count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_structure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       flat_sequence[i] = tensor_array_ops.build_ta_with_new_flow(\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        validation_batch_size=None,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        validation_data=None,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        \"\"\"Runs a single training step.\"\"\"\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        call_fn = tf.__internal__.autograph.tf_convert(self.call, tf.__internal__.autograph.control_status_ctx())\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        ag_fn = tf.__internal__.autograph.tf_convert(self.fn, tf.__internal__.autograph.control_status_ctx())\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1738, in sparse_categorical_crossentropy\n        y_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5114, in sparse_categorical_crossentropy\n        values of `predictions[i]`.\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P7U6r3A3ztE"
      },
      "source": [
        "# Use Callback to help make the prediction process more efficient\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "  images = None\n",
        "  labels = None\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "  normalize = lambda images: images / 255.0\n",
        "\n",
        "  mnist = tf.keras.datasets.fashion_mnist\n",
        "  training_data, test_data = Dataset(), Dataset()\n",
        "\n",
        "  (\n",
        "    (training_data.images, training_data.labels), \n",
        "    (test_data.images, test_data.labels)\n",
        "  ) = mnist.load_data()\n",
        "\n",
        "  training_data.images = normalize(training_data.images)\n",
        "  test_data.images = normalize(test_data.images)\n",
        "\n",
        "  return training_data, test_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajAFjL2E1xAt",
        "outputId": "37d623ff-c1ee-4bf4-c0c5-500c039c5880"
      },
      "source": [
        "training_data, test_data = load_dataset()\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.optimizers.Adam(),\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "  training_data.images,\n",
        "  training_data.labels,\n",
        "  epochs=10, callbacks=[callbacks]\n",
        ")\n",
        "\n",
        "print(\"history:\", history.epoch, history.history['accuracy'][-1])\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data.images, test_data.labels)\n",
        "\n",
        "print('-' * 20)\n",
        "print('Evaluate the loss and accuracy from the test set...')\n",
        "\n",
        "show = lambda s, value: print(\"{}: {}\".format(s, value))\n",
        "\n",
        "show(\"loss\", test_loss)\n",
        "show(\"accuracy\", test_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_13 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4701 - accuracy: 0.8337\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3546 - accuracy: 0.8708\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3209 - accuracy: 0.8819\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2994 - accuracy: 0.8897\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2811 - accuracy: 0.8949\n",
            "Epoch 6/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9026\n",
            "Reached 90% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2645 - accuracy: 0.9026\n",
            "history: [0, 1, 2, 3, 4, 5] 0.9026333093643188\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8770\n",
            "--------------------\n",
            "Evaluate the loss and accuracy from the test set...\n",
            "loss: 0.3430030643939972\n",
            "accuracy: 0.8769999742507935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YoQWTaQ7R7n"
      },
      "source": [
        "### Assignment 2: Handwriting Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEBn9X9B8ABg"
      },
      "source": [
        "Build a neural network that recognizes handwriting digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx4N134uG__Q",
        "outputId": "d82a7546-01c6-434e-821d-502085a70e12"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(\n",
        "  (x_train, y_train),\n",
        "  (x_test, y_test)\n",
        ") = mnist.load_data()\n",
        "\n",
        "print(\"shape of image:\", x_train[0].shape)\n",
        "print(y_train[0])\n",
        "\n",
        "print(y_train)\n",
        "print(len(y_train))\n",
        "\n",
        "print(\"shape of each image in the test dataset\", x_test[0].shape)\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of image: (28, 28)\n",
            "5\n",
            "[5 0 4 ... 5 6 8]\n",
            "60000\n",
            "shape of each image in the test dataset (28, 28)\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN-JrnPhLEA-"
      },
      "source": [
        "Taking a peek at the first character image of the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "MmMkzl9kEvHn",
        "outputId": "4a51408e-e231-490b-9f3a-95675100e3a1"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])\n",
        "\n",
        "print(y_train[0])\n",
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca-621yTK2__"
      },
      "source": [
        "Taking a quick peek at the test dataset by plotting the first character image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "2KEv_IOqIlln",
        "outputId": "f8e7e28a-328d-4bd8-8609-b833791a2072"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test[0])\n",
        "print(\"You should see the character image for: \", y_test[0])\n",
        "print(x_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You should see the character image for:  7\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMuHKCi97zOE"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ClFNorqzdC"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') is not None and logs.get('accuracy') > 0.99):\n",
        "      print(\"\\nReached 99% accuracy so canceling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, callbacks=callbacks)\n",
        "\n",
        "prediction = model.predict(\n",
        "    np.array([x_test[0]])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nRg5T5GOLU0",
        "outputId": "3eecc14d-c502-46ad-e7e8-6c0ac89ce9ee"
      },
      "source": [
        "from pprint import PrettyPrinter\n",
        "printer = PrettyPrinter(indent=4)\n",
        "\n",
        "print(prediction)\n",
        "print(x_test.shape)\n",
        "print(len(prediction))\n",
        "printer.pprint(prediction[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4.8845171e-31 5.1533913e-32 7.1893819e-14 5.1319662e-18 2.5981995e-30 6.2687669e-21 0.0000000e+00 1.0000000e+00 8.9352192e-26 1.8026431e-12]]\n",
            "(10000, 28, 28)\n",
            "1\n",
            "array([4.8845171e-31, 5.1533913e-32, 7.1893819e-14, 5.1319662e-18, 2.5981995e-30, 6.2687669e-21, 0.0000000e+00, 1.0000000e+00, 8.9352192e-26, 1.8026431e-12], dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP9UfHIGV11N"
      },
      "source": [
        "### Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqmhS8jNWF4N"
      },
      "source": [
        "1. Fashion MNIST\n",
        "1. 28x28 Greyscale\n",
        "1. 70,000 images in the Fashion MNIST dataset\n",
        "1. Why are there 10 output neurons? Is it because there are 10 different labels?\n",
        "1. What does Relu do?\n",
        "1. The data is split into training and test sets so that we can test a network with previously unseen data.\n",
        "1. The method that gets called when an epoch finishes is `on_epoch_end`.\n",
        "1. The parameter to set in your fit function to tell it to use callbacks is `callbacks=`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng0NdzXqYrpG"
      },
      "source": [
        "## Week 3: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nozjx4GySu6i"
      },
      "source": [
        "### Lab 1: Improving Computer Vision Accuracy using Convolutions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW1O_rQ4fEP7",
        "outputId": "7bf29cdd-436a-4199-b575-df82fa4a5f27"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"{} {}\".format(tf.__name__, tf.__version__))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdcFX9fhSldL",
        "outputId": "36dcb572-1f48-421e-da5c-29b3e3fb1c35"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normal both training and test data\n",
        "\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(training_images, training_labels, epochs=5)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4372 - accuracy: 0.8418\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2910 - accuracy: 0.8937\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2471 - accuracy: 0.9082\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2145 - accuracy: 0.9201\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1888 - accuracy: 0.9296\n",
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chief_worker_only', '_implements_predict_batch_hooks', '_implements_test_batch_hooks', '_implements_train_batch_hooks', '_keras_api_names', '_keras_api_names_v1', '_supports_tf_logs', 'epoch', 'history', 'model', 'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end', 'on_predict_batch_begin', 'on_predict_batch_end', 'on_predict_begin', 'on_predict_end', 'on_test_batch_begin', 'on_test_batch_end', 'on_test_begin', 'on_test_end', 'on_train_batch_begin', 'on_train_batch_end', 'on_train_begin', 'on_train_end', 'params', 'set_model', 'set_params', 'validation_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xr-2RGh9dzc",
        "outputId": "6fe443d7-620d-4b8c-fda1-425aae824e3b"
      },
      "source": [
        "from pprint import PrettyPrinter\n",
        "\n",
        "pp = PrettyPrinter(indent=4)\n",
        "pp.pprint(history.history)\n",
        "\n",
        "# The output should show the accuracy and loss values of the training data \n",
        "# from each epoch\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'accuracy': [   0.8418499827384949,\n",
            "                    0.8937166929244995,\n",
            "                    0.9081666469573975,\n",
            "                    0.9201333522796631,\n",
            "                    0.9296333193778992],\n",
            "    'loss': [   0.43722763657569885,\n",
            "                0.2909815013408661,\n",
            "                0.2470698058605194,\n",
            "                0.2145003378391266,\n",
            "                0.18876244127750397]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx-iOEiX48cr"
      },
      "source": [
        "This is what Training time looks like when not using a GPU:\n",
        "\n",
        "```\n",
        "Epoch 1/5\n",
        "1875/1875 [==============================] - 91s 48ms/step - loss: 0.4440 - accuracy: 0.8391\n",
        "Epoch 2/5\n",
        "1875/1875 [==============================] - 90s 48ms/step - loss: 0.3013 - accuracy: 0.8888\n",
        "Epoch 3/5\n",
        "1875/1875 [==============================] - 89s 47ms/step - loss: 0.2546 - accuracy: 0.9049\n",
        "Epoch 4/5\n",
        "1875/1875 [==============================] - 90s 48ms/step - loss: 0.2220 - accuracy: 0.9172\n",
        "Epoch 5/5\n",
        "1875/1875 [==============================] - 89s 48ms/step - loss: 0.1956 - accuracy: 0.9262\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCpoD9X3lTe6",
        "outputId": "fbdc21b7-22b9-4103-ec53-8480f102216d"
      },
      "source": [
        "# Check test accuracy of model\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"loss: {}\".format(test_loss))\n",
        "print(\"accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2666 - accuracy: 0.9038\n",
            "loss: 0.26656922698020935\n",
            "accuracy: 0.9038000106811523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeWHoqTRSxty"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUUgzmMvYvAs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}